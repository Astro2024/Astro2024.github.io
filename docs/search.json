[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\nfrom source import Perceptron\n\np= Perceptron()\n\nI did it!!\nFigure 1 is an image of the earth\nFigure 2 is a comic about Randall Munroe.\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/goal-setting/index.html",
    "href": "posts/goal-setting/index.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "James Hetherington\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would especially like to grow in the implementation and experimentation side of this class. Being a math major, I work endlessly with theory so I would be happy if I actually got to minimize this side of things. Then looking at the last three I have been working on personal automated algorithms as a project for the last two years and I have wanted to incorporate ml into its decision making frame work for the last year or so and have not felt like I had the tools to do so.\nTo recap, the implementation and experimentation most closely connect to what I plan on doing once I graduate this summer.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\n\nI plan on trying to complete almost every blog post we are assigned. This come with the acknowledgement that I have a busy schedule and I will be competing for the Track and Field team for the entire spring, so some assignments might have delayed publishing.\nI do not want to post any blog posts that are incomplete. I want to finish everything that is asked in the assignment and if I cannot figure something out I will write out a response I where I think I went wrong.\n\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\n\nI always want to ask questions during the class.\nTry to be in-person for every class, with the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance.\nComplete every warmup even if I am not able to make the class.\n\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\n\nProject 1: Implement a ML model for the automated algorithms I have been working on for the last 2 years\nProject 2: Create a program that takes audio file, classifies what language it is, translates the language to another language, then reads it back to the user.\n\nthis would be a complex problem that would include a lot of NLP, a course I am also currently in. I have various ideas on how to increase accuracy of translation while decreasing the time and space complexity of the model"
  },
  {
    "objectID": "posts/goal-setting/index.html#what-youll-learn",
    "href": "posts/goal-setting/index.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would especially like to grow in the implementation and experimentation side of this class. Being a math major, I work endlessly with theory so I would be happy if I actually got to minimize this side of things. Then looking at the last three I have been working on personal automated algorithms as a project for the last two years and I have wanted to incorporate ml into its decision making frame work for the last year or so and have not felt like I had the tools to do so.\nTo recap, the implementation and experimentation most closely connect to what I plan on doing once I graduate this summer."
  },
  {
    "objectID": "posts/goal-setting/index.html#what-youll-achieve",
    "href": "posts/goal-setting/index.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\n\nI plan on trying to complete almost every blog post we are assigned. This come with the acknowledgement that I have a busy schedule and I will be competing for the Track and Field team for the entire spring, so some assignments might have delayed publishing.\nI do not want to post any blog posts that are incomplete. I want to finish everything that is asked in the assignment and if I cannot figure something out I will write out a response I where I think I went wrong.\n\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\n\nI always want to ask questions during the class.\nTry to be in-person for every class, with the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance.\nComplete every warmup even if I am not able to make the class.\n\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\n\nProject 1: Implement a ML model for the automated algorithms I have been working on for the last 2 years\nProject 2: Create a program that takes audio file, classifies what language it is, translates the language to another language, then reads it back to the user.\n\nthis would be a complex problem that would include a lot of NLP, a course I am also currently in. I have various ideas on how to increase accuracy of translation while decreasing the time and space complexity of the model"
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html",
    "href": "posts/classifying-palmer-penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\n\nAbstract\n\n\nIn this post I hope to explore the penguin data set and find a combination of variables that will give us the highest accurate rate when trying to predict the species of a penguin. I will start by cleaning up the data and exploring a few visual representation in order to gain insight into some of the most notable variables for species prediction. Then pairing those insights with an exhaustive search, I will find the most effective model(s) and graph their decision boundaries.\n\n#import libraries\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\n#Importing training data\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\n#Data Preparation\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\nl = LabelEncoder()\nl.fit(train[\"Island\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Sex\", \"Clutch Completion\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\ncolumns = []\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    columns.append(cols) \n\n\n#Additional data preperation for graphics\nd = train[train[\"Sex\"] != \".\"]\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    d[\"Species\"] = d[\"Species\"].str.split().str.get(0)\n    d[\"Islands\"] = l.transform(d[\"Island\"])\n\n\nThe following graphs are a combination of scatterplots exploring the effectiveness of stratifying the penguin population by Islands x random variable and collection of boxplots exploring the range of flipper length amongs the different species. The plots show that if any penguin is found on Torgersen it will be an Adelie. They also show Adelie and Gentoo are easily distinguishable using islands and most other variable, the most effective being Flipper Length. On the other hand, Chinstrap and Adelie are much harder to distinguish between, the variable Delta 13 C is probably the best variable for trying to differentiate between Chinstrap and Adelie. However, all around, the best variable to pair with Islands is the Culmen Length.\n\nimport seaborn as sns\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 10))\np1 = sns.scatterplot(d, x = \"Islands\", y = \"Delta 13 C (o/oo)\", hue = \"Species\", ax = ax[0,0])\np2 = sns.scatterplot(d, x = \"Islands\", y = \"Flipper Length (mm)\", hue = \"Species\", ax = ax[0,1])\np3 = sns.scatterplot(d, x = \"Islands\", y = \"Body Mass (g)\", hue = \"Species\", ax = ax[1,0])\np4 = sns.scatterplot(d, x = \"Islands\", y = \"Culmen Length (mm)\", hue = \"Species\", ax = ax[1,1])\n\np5 = sns.catplot(data=d, kind=\"bar\", x=\"Island\", y=\"Flipper Length (mm)\", hue=\"Species\")\np6 = sns.displot(d, x=\"Flipper Length (mm)\", col=\"Species\", row=\"Sex\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#Finds the best pairing of variables\nbest = ([], 0)\nfrom sklearn.exceptions import ConvergenceWarning\n\nfor x in columns:\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[x]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\n        if score &gt; best[1]:\n            best = (x, score)\n        elif score == best[1]:\n            print(x, score)\nprint(best[0], best[1])\n\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Culmen Depth (mm)'] 0.99609375\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)'] 0.99609375\n\n\n\nThe code above finds the best pairing of three variables. As there are two best pairing, in the code below we train two different models. One for the variables Culmen Length (mm), Culmen Depth (mm), and Sex. The other for Culmen Length (mm), Culmen Depth (mm), and Islands.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nX_test.head()\n\nLR1 = LogisticRegression()\nLR2 = LogisticRegression()\n\ncols1 = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_FEMALE', 'Sex_MALE',]\ncols2 = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n    mf1 = LR1.fit(X_train[cols1], y_train)\n    ms1 = LR1.score(X_test[cols1], y_test)\n    mf2 = LR2.fit(X_train[cols2], y_train)\n    ms2 = LR2.score(X_test[cols2], y_test)\n\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#Plots the decision regions for our two model on the training data\nplot_regions(LR1, X_train[cols1], y_train)\nplot_regions(LR2, X_train[cols2], y_train)\n#Plots the decision regions for our two model on the testing data\nplot_regions(LR1, X_test[cols1], y_test)\nplot_regions(LR2, X_test[cols2], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred1 = LR1.predict(X_test[cols1])\ny_test_pred2 = LR2.predict(X_test[cols2])\nC1 = confusion_matrix(y_test, y_test_pred1)\nC2 = confusion_matrix(y_test, y_test_pred2)\nprint(C1, \"First Model\")\nprint(C2, \"Second Model\")\n\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]] First Model\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]] Second Model\n\n\n\nThere are no errors in either of the models on the dest data. However, looking at the training and test decision regions I would guess the most common errors come between Adelie and Gentoo predictions.\n\nDiscussion:\n\n\nIn this project I have explored a variety of variable combinations and founds two different combinations of three variables that are able to predict penguin species from a test set with a success rate of 100%. With only two variable, depending on which are chosen, it becomes easier to distinguish one of the species but the other two tend to be muddled. However, with the introduction of a third variable the two remaining species become easier to distinguish between. Using the combinations [Culmen Length (mm), Culmen Depth (mm), Sex] and [Culmen Length (mm), Culmen Depth (mm), Islands] we achieve the highest prediction accuracy for penguin species. On the training data we achieve a joint accuracy rate of 99.61% and a success rate of 100% on the test data."
  },
  {
    "objectID": "posts/optimal-descision-making/index.html",
    "href": "posts/optimal-descision-making/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\n\nPart A:\n\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\nPart B:\n\n\n#Data Preparation\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df_train['person_home_ownership'])\nl = LabelEncoder()\nl.fit(df_train['loan_intent'])\nld = LabelEncoder()\nld.fit(df_train['loan_grade'])\n\ndef prepare_data(df):\n  df = df.dropna()\n  y = df['loan_status']\n  #df[\"home_ownership\"] = df[\"person_home_ownership\"]\n  #df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\nX_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\n...\nloan_intent_VENTURE\nloan_grade_A\nloan_grade_B\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0\n0.12\n6\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0\n0.27\n4\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n1\n0.05\n4\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0\n0.28\n10\nTrue\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n1\n0.25\n2\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n5 rows × 27 columns\n\n\n\n\n\nX_train[\"person_age\"].min()\n\n20\n\n\n\nimport seaborn as sns\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 10))\np1 = sns.scatterplot(df_train, x = \"person_age\", y = \"person_income\", hue = \"loan_status\", ax = ax[0,0])\np2 = sns.scatterplot(df_train, x = \"loan_intent\", y = \"person_emp_length\", hue = \"loan_status\", ax = ax[0,1])\np3 = sns.scatterplot(df_train, x = \"loan_amnt\", y = \"loan_int_rate\", hue = \"loan_status\", ax = ax[1,0])\np4 = sns.scatterplot(df_train, x = \"loan_percent_income\", y = \"cb_person_cred_hist_length\", hue = \"loan_status\", ax = ax[1,1])\n\np5 = sns.catplot(data=df_train, kind=\"bar\", x=\"person_home_ownership\", y=\"loan_amnt\", hue=\"loan_status\")\n#p6 = sns.displot(df_train, x=\"loan_int_rate\", col=\"loan_status\", row=\"person_home_ownership\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart C:\n\n\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\nall_quant_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\ncolumns = []\nfor qual in combinations(all_qual_cols, 1): \n  qual_cols1 = [col for col in X_train.columns if qual[0] in col ]\n  #qual_cols2 = [col for col in X_train.columns if qual[1] in col ]\n  #qual_cols3 = [col for col in X_train.columns if qual[2] in col ]\n  for pair in combinations(all_quant_cols, 1):\n    cols = qual_cols1 + list(pair) \n    #cols = qual_cols1 + qual_cols2 + list(pair) \n    #cols = qual_cols1 + qual_cols2 + qual_cols3 + list(pair) \n    columns.append(cols) \n#Finds the best pairing of variables\nbest1 = ([], 0)\nbest2 = ([], 0)\nfrom sklearn.exceptions import ConvergenceWarning\n\nfor x in columns:\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[x]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\n        if score &gt; best1[1]:\n            best2 = best1\n            best1 = (x, score)\n        elif score == best1[1]:\n            print(x, score)\nprint(best1[1], best1[0])\nprint(best2[1], best2[0])\n\n0.8492600515126381 ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_percent_income']\n0.817217444449295 ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_int_rate']\n\n\n\nbest_vars = ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_percent_income']\nwith warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[best_vars]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\nweights = LR.coef_\nweights\n\narray([[-0.76352014, -0.10753429, -1.80005286,  0.27250832,  8.27561064]])\n\n\n\ndef linear_score(df, w, x):\n    sum = 0\n    for i in range(len(x)):\n        sum += w[0][i]*df[x[i]]\n    return sum\nlscores = linear_score(X_train, weights, best_vars)\nhist = plt.hist(lscores)\n\n\n\n\n\n\n\n\n\ndef predict(score_fun, w, x, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(df, w, x)\n    return 1*(scores &gt; threshold)\n\n\nPart D:\n\n\nacc = []\nfor t in np.linspace(lscores.min()-.01, lscores.max()+.01, 101):\n    y_pred = lscores &gt;= t\n    ac = (y_pred == y_train).mean()\n    acc = acc + [(y_pred == y_train).mean()]\n    print(f\"A threshold of {t:.2f} gives an accuracy of {ac:.3f}.\")\n#2.6 - 2.8 best threshold for accuracy\n\nA threshold of -1.73 gives an accuracy of 0.215.\nA threshold of -1.64 gives an accuracy of 0.215.\nA threshold of -1.56 gives an accuracy of 0.216.\nA threshold of -1.48 gives an accuracy of 0.218.\nA threshold of -1.39 gives an accuracy of 0.220.\nA threshold of -1.31 gives an accuracy of 0.223.\nA threshold of -1.22 gives an accuracy of 0.225.\nA threshold of -1.14 gives an accuracy of 0.228.\nA threshold of -1.06 gives an accuracy of 0.230.\nA threshold of -0.97 gives an accuracy of 0.233.\nA threshold of -0.89 gives an accuracy of 0.239.\nA threshold of -0.81 gives an accuracy of 0.242.\nA threshold of -0.72 gives an accuracy of 0.245.\nA threshold of -0.64 gives an accuracy of 0.250.\nA threshold of -0.55 gives an accuracy of 0.258.\nA threshold of -0.47 gives an accuracy of 0.271.\nA threshold of -0.39 gives an accuracy of 0.286.\nA threshold of -0.30 gives an accuracy of 0.305.\nA threshold of -0.22 gives an accuracy of 0.323.\nA threshold of -0.13 gives an accuracy of 0.342.\nA threshold of -0.05 gives an accuracy of 0.359.\nA threshold of 0.03 gives an accuracy of 0.375.\nA threshold of 0.12 gives an accuracy of 0.392.\nA threshold of 0.20 gives an accuracy of 0.409.\nA threshold of 0.28 gives an accuracy of 0.425.\nA threshold of 0.37 gives an accuracy of 0.443.\nA threshold of 0.45 gives an accuracy of 0.459.\nA threshold of 0.54 gives an accuracy of 0.482.\nA threshold of 0.62 gives an accuracy of 0.502.\nA threshold of 0.70 gives an accuracy of 0.525.\nA threshold of 0.79 gives an accuracy of 0.545.\nA threshold of 0.87 gives an accuracy of 0.568.\nA threshold of 0.95 gives an accuracy of 0.592.\nA threshold of 1.04 gives an accuracy of 0.614.\nA threshold of 1.12 gives an accuracy of 0.637.\nA threshold of 1.21 gives an accuracy of 0.657.\nA threshold of 1.29 gives an accuracy of 0.679.\nA threshold of 1.37 gives an accuracy of 0.701.\nA threshold of 1.46 gives an accuracy of 0.717.\nA threshold of 1.54 gives an accuracy of 0.733.\nA threshold of 1.63 gives an accuracy of 0.745.\nA threshold of 1.71 gives an accuracy of 0.759.\nA threshold of 1.79 gives an accuracy of 0.770.\nA threshold of 1.88 gives an accuracy of 0.781.\nA threshold of 1.96 gives an accuracy of 0.794.\nA threshold of 2.04 gives an accuracy of 0.805.\nA threshold of 2.13 gives an accuracy of 0.812.\nA threshold of 2.21 gives an accuracy of 0.821.\nA threshold of 2.30 gives an accuracy of 0.827.\nA threshold of 2.38 gives an accuracy of 0.835.\nA threshold of 2.46 gives an accuracy of 0.838.\nA threshold of 2.55 gives an accuracy of 0.843.\nA threshold of 2.63 gives an accuracy of 0.846.\nA threshold of 2.72 gives an accuracy of 0.849.\nA threshold of 2.80 gives an accuracy of 0.853.\nA threshold of 2.88 gives an accuracy of 0.847.\nA threshold of 2.97 gives an accuracy of 0.841.\nA threshold of 3.05 gives an accuracy of 0.834.\nA threshold of 3.13 gives an accuracy of 0.829.\nA threshold of 3.22 gives an accuracy of 0.825.\nA threshold of 3.30 gives an accuracy of 0.820.\nA threshold of 3.39 gives an accuracy of 0.818.\nA threshold of 3.47 gives an accuracy of 0.814.\nA threshold of 3.55 gives an accuracy of 0.811.\nA threshold of 3.64 gives an accuracy of 0.806.\nA threshold of 3.72 gives an accuracy of 0.804.\nA threshold of 3.80 gives an accuracy of 0.801.\nA threshold of 3.89 gives an accuracy of 0.799.\nA threshold of 3.97 gives an accuracy of 0.797.\nA threshold of 4.06 gives an accuracy of 0.796.\nA threshold of 4.14 gives an accuracy of 0.795.\nA threshold of 4.22 gives an accuracy of 0.793.\nA threshold of 4.31 gives an accuracy of 0.792.\nA threshold of 4.39 gives an accuracy of 0.791.\nA threshold of 4.48 gives an accuracy of 0.790.\nA threshold of 4.56 gives an accuracy of 0.789.\nA threshold of 4.64 gives an accuracy of 0.788.\nA threshold of 4.73 gives an accuracy of 0.788.\nA threshold of 4.81 gives an accuracy of 0.787.\nA threshold of 4.89 gives an accuracy of 0.787.\nA threshold of 4.98 gives an accuracy of 0.787.\nA threshold of 5.06 gives an accuracy of 0.787.\nA threshold of 5.15 gives an accuracy of 0.787.\nA threshold of 5.23 gives an accuracy of 0.786.\nA threshold of 5.31 gives an accuracy of 0.786.\nA threshold of 5.40 gives an accuracy of 0.786.\nA threshold of 5.48 gives an accuracy of 0.786.\nA threshold of 5.57 gives an accuracy of 0.786.\nA threshold of 5.65 gives an accuracy of 0.785.\nA threshold of 5.73 gives an accuracy of 0.785.\nA threshold of 5.82 gives an accuracy of 0.785.\nA threshold of 5.90 gives an accuracy of 0.785.\nA threshold of 5.98 gives an accuracy of 0.785.\nA threshold of 6.07 gives an accuracy of 0.785.\nA threshold of 6.15 gives an accuracy of 0.785.\nA threshold of 6.24 gives an accuracy of 0.785.\nA threshold of 6.32 gives an accuracy of 0.785.\nA threshold of 6.40 gives an accuracy of 0.785.\nA threshold of 6.49 gives an accuracy of 0.785.\nA threshold of 6.57 gives an accuracy of 0.785.\nA threshold of 6.65 gives an accuracy of 0.785.\n\n\n\nfrom sklearn.metrics import confusion_matrix\nfig, ax = plt.subplots(1, 1, figsize = (6, 4))\n\nnum_thresholds = 101\n\nFPR = np.zeros(num_thresholds)\nTPR = np.zeros(num_thresholds)\nconfusions = []\nT = np.linspace(lscores.min()-0.1, lscores.max()+0.1, num_thresholds)\ns = linear_score(X_train, weights, best_vars)\n\nfor i in range(num_thresholds):\n    t = T[i]\n    preds = s &gt;= t\n    FPR[i] = ((preds == 1) & (y_train == 0)).sum() / (y_train == 0).sum()\n    TPR[i] = ((preds == 1) & (y_train == 1)).sum() / (y_train == 1).sum()\n    confusions.append(confusion_matrix(y_train, preds))\n\n\nax.plot(FPR, TPR, color = \"black\")\nax.plot([0,1], [0,1], linestyle=\"--\", color = \"grey\")\nax.set_aspect('equal')\n\nlabs = ax.set(xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", title = \"ROC Curve\")\n\n\n\n\n\n\n\n\n\nX_train[\"bank_profit_repaid\"] = X_train[\"loan_amnt\"]*(1 + 0.25*(X_train[\"loan_int_rate\"]/100))**10 - X_train[\"loan_amnt\"]\nX_train[\"bank_profit_default\"] = X_train[\"loan_amnt\"]*(1 + 0.25*(X_train[\"loan_int_rate\"]/100))**3 - 1.7*X_train[\"loan_amnt\"]\n\n\ngood_choice = []\nbad_choice = []\nprob_0 = (confusions[1][0][0]+confusions[1][0][1])/confusions[1].sum()\nprob_1 = (confusions[1][1][0]+confusions[1][1][1])/confusions[1].sum()\nfor x in confusions:\n    good_choice.append(float(x[0][0]))\n    bad_choice.append(float(x[1][0]))\n\n\nTNR = 1 - FPR\nFNR = 1 - TPR\n\ncost_of_FN = X_train[\"bank_profit_default\"]\ngain_of_TN = X_train[\"bank_profit_repaid\"]\n#This has the same maximum as the equation below, however it does not show the E[] per loan\n#gain =  gain_of_TN.mean()*np.array(good_choice)  + cost_of_FN.mean()*np.array(bad_choice)\n\n# I was looking at the fourth set of notes from class and was confused at the equation we were using to calculate gain.\n# It did not seem to give us any useful information gain, so I figured there might be an error. I look online and found\n# a gain equation that was what was mentioned in class but now normalized (https://medium.com/@overfittedcat/expected-value-as-evaluation-metric-in-machine-learning-b3836511cd)\ngain = prob_0*(gain_of_TN.mean() * TNR) + prob_1*(cost_of_FN.mean() * FNR)\n\n# Gain function from notes\n#gain = (gain_of_TN.mean() * TNR) + (cost_of_FN.mean() * FNR)\n\nplt.plot(T, gain)\n\n#The following function I found online for annotating the maximum point\ndef annot_max(x,y, ax=None):\n    xmax = x[np.argmax(y)]\n    ymax = y.max()\n    text= \"x={:.3f}, y={:.3f}\".format(xmax, ymax)\n    if not ax:\n        ax=plt.gca()\n    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n    arrowprops=dict(arrowstyle=\"-&gt;\",connectionstyle=\"angle,angleA=0,angleB=60\")\n    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.96), **kw)\n\nannot_max(T,gain)\nplt.gca().set(ylim = (-300, 2000), xlim = (-2, 7))\nlabs = plt.gca().set(xlabel = r\"Threshold $t$\", ylabel = \"Expected profit per loan\")\n\n\n\n\n\n\n\n\n\nplt.plot(T, acc)\nannot_max(T, np.array(acc))\nplt.gca().set(ylim = (0, 1), xlim = (-2, 7))\nlabs = plt.gca().set(xlabel = r\"Threshold $t$\", ylabel = \"Accuracy\")\n\n\n\n\n\n\n\n\nIn this section I created a gain function using the average gain on a fully repaid loan and the average loss on a defaulted loan. After examining the expected gain function we were given in class, I felt like it did not provide us with any substantial information gain, so I researched expected value functions and found a version of the in-class function that was normalized. The two graphs above show the optimal threshold for accuracy and expected profit per loan. For both the maximizing threshold was 2.806 and it brought our accuracy up to 85.3% and our expected profit per loan to $1614.14.\n\nPart: E\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\nX_test, y_test = prepare_data(df_test)\n\nX_test[\"bank_profit_repaid\"] = X_test[\"loan_amnt\"]*(1 + 0.25*(X_test[\"loan_int_rate\"]/100))**10 - X_test[\"loan_amnt\"]\nX_test[\"bank_profit_default\"] = X_test[\"loan_amnt\"]*(1 + 0.25*(X_test[\"loan_int_rate\"]/100))**3 - 1.7*X_test[\"loan_amnt\"]\n\n\n\ny_predicted = predict(linear_score, weights, best_vars, 2.806, X_test)\ndf_test[\"test_predicted\"] = y_predicted\ninvert = (y_predicted + 1) % 2\n\ngaint = (X_test[\"bank_profit_default\"] * y_predicted) + (X_test[\"bank_profit_repaid\"] * invert)\nprint(gaint.mean())\n\nFPR1   = ((y_predicted == 1) & (y_test == 0)).sum() / (y_test == 0).sum()\nTPR1   = ((y_predicted == 1) & (y_test == 1)).sum() / (y_test == 1).sum()\n\nTNR1 = 1 - FPR1\nFNR1 = 1 - TPR1\n\nconfuse = confusion_matrix(y_test, y_predicted)\n\nprob_zero = (confuse[0][0]+confuse[0][1])/confuse.sum()\nprob_one = (confuse[1][0]+confuse[1][1])/confuse.sum()\n\ngain_test = prob_zero*(X_test[\"bank_profit_repaid\"].mean() * TNR1) + prob_one*(X_test[\"bank_profit_default\"].mean() * FNR1)\ngain_test\n\n1966.832456892238\n\n\n1605.4481388536585\n\n\n\n1 - 1605.448/1614.137 \n\n0.005383062280339135\n\n\nThe expected gain for the test data set is very close to our train data set. The training set was 1614.137 and our test set is 1605.448. That is only a $8.69 difference. From the banks perspective the weights and threshold we selected were only .5% off which is pretty good.\n\nPart F:\n\n#sns.catplot(data=df_test, kind=\"bar\", x=\"person_age\", y=\"test_predicted\")\n#sns.scatterplot(df_test, x = \"person_age\", y = \"test_predicted\")\n\ntr = df_test.groupby(\"person_age\").aggregate(\"test_predicted\").mean()\nsns.scatterplot(tr)\n\n\n\n\n\n\n\n\n\n\n\nintent_predicted = df_test.groupby(\"loan_intent\").aggregate(\"test_predicted\").mean()\nintent_real = df_test.groupby(\"loan_intent\").aggregate(\"loan_status\").mean()\nprint(intent_predicted)\nprint(intent_real)\n\nloan_intent\nDEBTCONSOLIDATION    0.095133\nEDUCATION            0.075680\nHOMEIMPROVEMENT      0.037338\nMEDICAL              0.102516\nPERSONAL             0.087174\nVENTURE              0.079876\nName: test_predicted, dtype: float64\nloan_intent\nDEBTCONSOLIDATION    0.279497\nEDUCATION            0.167421\nHOMEIMPROVEMENT      0.246088\nMEDICAL              0.281553\nPERSONAL             0.219227\nVENTURE              0.145701\nName: loan_status, dtype: float64\n\n\n\nprint(\"mean\", df_test.groupby(\"test_predicted\").aggregate(\"person_income\").mean())\nprint(\"median\", df_test.groupby(\"test_predicted\").aggregate(\"person_income\").median())\n\nmean test_predicted\n0.0    69033.762122\n1.0    39483.673729\nName: person_income, dtype: float64\nmedian test_predicted\n0.0    58700.0\n1.0    36000.0\nName: person_income, dtype: float64\n\n\n\nIs it more difficult for people in certain age groups to access credit under your proposed system?\n\nFor the most part as you get older the more likely you are to get access to credit\n\nIs it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\n\nCompared to other intents, medical loans are predicted to be the most likely to default under my model. In the actual data medical loans also have the highest default rate. Across the board my model is more lenient when it comes to loan default prediction.\n\nHow does a person’s income level impact the ease with which they can access credit under your decision system?\n\nThe lower someone’s income the more likely they are to be predicted to default.\n\n\n\nPart G:"
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "CSCI 0451: Reflective Goal-Setting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMid-Course Reflection\n\n\n\n\n\nWe reflect on our learning, engagement, and achievement in the first part of the semester. \n\n\n\n\n\nApr 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nA blog post exploring predictive variables for penguin species\n\n\n\n\n\nMar 28, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nA blog post exploring predictive variables for penguin species\n\n\n\n\n\nMar 28, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/mid-course/index.html",
    "href": "posts/mid-course/index.html",
    "title": "Mid-Course Reflection",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "posts/mid-course/index.html#the-data",
    "href": "posts/mid-course/index.html#the-data",
    "title": "Mid-Course Reflection",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\n*How often have you attended class?\n\nI have missed three classes this semester, but two of those were thursday classes I missed due leaving for a track meet early.\n\nHow often have you taken notes on the core readings ahead of the class period? ____\n\nI do not take note on readings before class. In computer science classes I internalize work best when I am actually coding or doing assignments, so I have spent more effort on doing all of the warmup assignements.\n\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called?\n\nThere have been two classes where I was not prepared present the warmup\n\nHow many times have you actually presented the daily warm-up to your team?\n\nI believe I have presented 4-5 times (our leader is often gone and we randomize the leader)\n\nHow many times have you asked your team for help while presenting the daily warm-up?\n\nTwice, they were the two classes I was not prepared to present. However, both times after discussing with teammates I ended up presenting.\n\nHow often have you learned something new from a teammate’s presentation of the daily warm-up?\n\nI do not think their presentation to the class has taught me something new, but in our group discussion I think I learn something new almost ever class.\n\nHow often have you helped a teammate during the daily warm-up presentation?\n\nConfused about “help”. Every presentation we discuss how we want to synthesize or present the content as a group, then the leader presents\n\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help?\n\nI have not. Office hour times tend to be during my other classes or track practice.\n\nHow often have you asked for or received help from your fellow students?\n\nI have not asked for help on an assignment out of the class\n\nHave you been regularly participating in a study group outside class?\n\nI do not participate in study groups outside of class.\n\nHow often have you posted questions or answers in Slack?\n\nI have not posted question on slack. When I have had questions I tend to talk with professor in-person.\n\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted?\n\nTechnically none. I have not been able to get quarto to work, however I just talked with the Professor today about the assignments (which I have completed) and Quarto so in the next day or two I should have 3 assignments turned in.\n\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 0\nM: Revisions useful: 0\nR: Revisions encouraged: 0\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? 7 hours a week"
  },
  {
    "objectID": "posts/mid-course/index.html#what-youve-learned",
    "href": "posts/mid-course/index.html#what-youve-learned",
    "title": "Mid-Course Reflection",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\n\nI have focussed mainly on Implementation and Experimentation. Outside of class I have been exploring how to integrate ML into a automated trading algorithm that I have managed over the last two years."
  },
  {
    "objectID": "posts/mid-course/index.html#reflecting-on-goals",
    "href": "posts/mid-course/index.html#reflecting-on-goals",
    "title": "Mid-Course Reflection",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal for this semester was to complete every blog we are assigned. I knew this was an ambitious, however I wanted to challenge myself and gain a concrete understanding of all the concepts. So far, if we were looking at canvas, I am very far behind. But, in actuality I have completed three of the six main blog posts. The reason I have been unable to submit the links is a 404 problem connected to quarto’s system. I am pretty confident that I can finish the remaining 3 post in the remaining weeks. I plan to finish one post each week for the next three weeks.\nMy one main regret so far this semester is that I was unable to make the women in data science conference. My track schedule this semester has been extremely hectic and I ended up having a mandatory track commitment on the same day as the conference.\n\n\nCourse Presence (Participation)\nIn my course presence section for goal setting I talked about trying to ask questions in class, make it to every class ith the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance, and to Complete every warmup even if I am not able to make the class. While I have missed three classes two of them fall into the “sports competition” category and the other class I missed was do to being sick. The one section I think I need to do better on is completing all of the warm ups. I have had a few warmup I did not complete and I did not have a valid reason other than being busy with other work.\n\n\nProject\nBoth project ideas I have talked about and presented in the last couple of weeks have been completely inline with the project ideas I mention in my initial goal setting.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\nI would love to have more in-class work using neural networks.\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nI would like to stick with all of the current goals I have. I feel like all of them are still very attainable and not too difficult to achieve."
  },
  {
    "objectID": "posts/mid-course/index.html#grade-and-goals",
    "href": "posts/mid-course/index.html#grade-and-goals",
    "title": "Mid-Course Reflection",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B+\n\n\nA way in which I resonate with the soundbytes for that grade above is… The reason I would not give myself an A- or A is because I do not think I have truly maximized my time in this class. I have had a busy schedule and have not spent the amount of effort I really want to. I strongly resonate with the soundbyte, “I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”"
  },
  {
    "objectID": "posts/mid-course/index.html#optional-how-to-improve",
    "href": "posts/mid-course/index.html#optional-how-to-improve",
    "title": "Mid-Course Reflection",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  }
]