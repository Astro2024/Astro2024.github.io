[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\nfrom source import Perceptron\n\np= Perceptron()\n\nI did it!!\nFigure 1 is an image of the earth\nFigure 2 is a comic about Randall Munroe.\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/goal-setting/index.html",
    "href": "posts/goal-setting/index.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "James Hetherington\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would especially like to grow in the implementation and experimentation side of this class. Being a math major, I work endlessly with theory so I would be happy if I actually got to minimize this side of things. Then looking at the last three I have been working on personal automated algorithms as a project for the last two years and I have wanted to incorporate ml into its decision making frame work for the last year or so and have not felt like I had the tools to do so.\nTo recap, the implementation and experimentation most closely connect to what I plan on doing once I graduate this summer.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\n\nI plan on trying to complete almost every blog post we are assigned. This come with the acknowledgement that I have a busy schedule and I will be competing for the Track and Field team for the entire spring, so some assignments might have delayed publishing.\nI do not want to post any blog posts that are incomplete. I want to finish everything that is asked in the assignment and if I cannot figure something out I will write out a response I where I think I went wrong.\n\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\n\nI always want to ask questions during the class.\nTry to be in-person for every class, with the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance.\nComplete every warmup even if I am not able to make the class.\n\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\n\nProject 1: Implement a ML model for the automated algorithms I have been working on for the last 2 years\nProject 2: Create a program that takes audio file, classifies what language it is, translates the language to another language, then reads it back to the user.\n\nthis would be a complex problem that would include a lot of NLP, a course I am also currently in. I have various ideas on how to increase accuracy of translation while decreasing the time and space complexity of the model"
  },
  {
    "objectID": "posts/goal-setting/index.html#what-youll-learn",
    "href": "posts/goal-setting/index.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would especially like to grow in the implementation and experimentation side of this class. Being a math major, I work endlessly with theory so I would be happy if I actually got to minimize this side of things. Then looking at the last three I have been working on personal automated algorithms as a project for the last two years and I have wanted to incorporate ml into its decision making frame work for the last year or so and have not felt like I had the tools to do so.\nTo recap, the implementation and experimentation most closely connect to what I plan on doing once I graduate this summer."
  },
  {
    "objectID": "posts/goal-setting/index.html#what-youll-achieve",
    "href": "posts/goal-setting/index.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\n\nI plan on trying to complete almost every blog post we are assigned. This come with the acknowledgement that I have a busy schedule and I will be competing for the Track and Field team for the entire spring, so some assignments might have delayed publishing.\nI do not want to post any blog posts that are incomplete. I want to finish everything that is asked in the assignment and if I cannot figure something out I will write out a response I where I think I went wrong.\n\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\n\nI always want to ask questions during the class.\nTry to be in-person for every class, with the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance.\nComplete every warmup even if I am not able to make the class.\n\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\n\nProject 1: Implement a ML model for the automated algorithms I have been working on for the last 2 years\nProject 2: Create a program that takes audio file, classifies what language it is, translates the language to another language, then reads it back to the user.\n\nthis would be a complex problem that would include a lot of NLP, a course I am also currently in. I have various ideas on how to increase accuracy of translation while decreasing the time and space complexity of the model"
  },
  {
    "objectID": "posts/mid-course/index.html",
    "href": "posts/mid-course/index.html",
    "title": "Mid-Course Reflection",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "posts/mid-course/index.html#the-data",
    "href": "posts/mid-course/index.html#the-data",
    "title": "Mid-Course Reflection",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\n*How often have you attended class?\n\nI have missed three classes this semester, but two of those were thursday classes I missed due leaving for a track meet early.\n\nHow often have you taken notes on the core readings ahead of the class period? ____\n\nI do not take note on readings before class. In computer science classes I internalize work best when I am actually coding or doing assignments, so I have spent more effort on doing all of the warmup assignements.\n\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called?\n\nThere have been two classes where I was not prepared present the warmup\n\nHow many times have you actually presented the daily warm-up to your team?\n\nI believe I have presented 4-5 times (our leader is often gone and we randomize the leader)\n\nHow many times have you asked your team for help while presenting the daily warm-up?\n\nTwice, they were the two classes I was not prepared to present. However, both times after discussing with teammates I ended up presenting.\n\nHow often have you learned something new from a teammate’s presentation of the daily warm-up?\n\nI do not think their presentation to the class has taught me something new, but in our group discussion I think I learn something new almost ever class.\n\nHow often have you helped a teammate during the daily warm-up presentation?\n\nConfused about “help”. Every presentation we discuss how we want to synthesize or present the content as a group, then the leader presents\n\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help?\n\nI have not. Office hour times tend to be during my other classes or track practice.\n\nHow often have you asked for or received help from your fellow students?\n\nI have not asked for help on an assignment out of the class\n\nHave you been regularly participating in a study group outside class?\n\nI do not participate in study groups outside of class.\n\nHow often have you posted questions or answers in Slack?\n\nI have not posted question on slack. When I have had questions I tend to talk with professor in-person.\n\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted?\n\nTechnically none. I have not been able to get quarto to work, however I just talked with the Professor today about the assignments (which I have completed) and Quarto so in the next day or two I should have 3 assignments turned in.\n\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 0\nM: Revisions useful: 0\nR: Revisions encouraged: 0\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? 7 hours a week"
  },
  {
    "objectID": "posts/mid-course/index.html#what-youve-learned",
    "href": "posts/mid-course/index.html#what-youve-learned",
    "title": "Mid-Course Reflection",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\n\nI have focussed mainly on Implementation and Experimentation. Outside of class I have been exploring how to integrate ML into a automated trading algorithm that I have managed over the last two years."
  },
  {
    "objectID": "posts/mid-course/index.html#reflecting-on-goals",
    "href": "posts/mid-course/index.html#reflecting-on-goals",
    "title": "Mid-Course Reflection",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal for this semester was to complete every blog we are assigned. I knew this was an ambitious, however I wanted to challenge myself and gain a concrete understanding of all the concepts. So far, if we were looking at canvas, I am very far behind. But, in actuality I have completed three of the six main blog posts. The reason I have been unable to submit the links is a 404 problem connected to quarto’s system. I am pretty confident that I can finish the remaining 3 post in the remaining weeks. I plan to finish one post each week for the next three weeks.\nMy one main regret so far this semester is that I was unable to make the women in data science conference. My track schedule this semester has been extremely hectic and I ended up having a mandatory track commitment on the same day as the conference.\n\n\nCourse Presence (Participation)\nIn my course presence section for goal setting I talked about trying to ask questions in class, make it to every class ith the acknowledgement that I will have job interviews, sports competitions, and family situations that might hinder my attendance, and to Complete every warmup even if I am not able to make the class. While I have missed three classes two of them fall into the “sports competition” category and the other class I missed was do to being sick. The one section I think I need to do better on is completing all of the warm ups. I have had a few warmup I did not complete and I did not have a valid reason other than being busy with other work.\n\n\nProject\nBoth project ideas I have talked about and presented in the last couple of weeks have been completely inline with the project ideas I mention in my initial goal setting.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\nI would love to have more in-class work using neural networks.\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nI would like to stick with all of the current goals I have. I feel like all of them are still very attainable and not too difficult to achieve."
  },
  {
    "objectID": "posts/mid-course/index.html#grade-and-goals",
    "href": "posts/mid-course/index.html#grade-and-goals",
    "title": "Mid-Course Reflection",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B+\n\n\nA way in which I resonate with the soundbytes for that grade above is… The reason I would not give myself an A- or A is because I do not think I have truly maximized my time in this class. I have had a busy schedule and have not spent the amount of effort I really want to. I strongly resonate with the soundbyte, “I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”"
  },
  {
    "objectID": "posts/mid-course/index.html#optional-how-to-improve",
    "href": "posts/mid-course/index.html#optional-how-to-improve",
    "title": "Mid-Course Reflection",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "posts/logistic-regression/index.html",
    "href": "posts/logistic-regression/index.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n Abstract: \nIn this blog post we will work to implement gradient descent for logistic regression in an object-oriented paradigm, set up a key variant of gradient descent which utilizes “momentum” in order to achieve faster convergence, and perform various experiments to exhibit the behavior or traditional gradient descent, the strength of momentum, and the dangers of overfitting. We hope that by the end of this post reader will have a better understanding or how the model functions and how we can utilize it.\nI have attached below a link to my source code for the LogisticRegression and GradientDescentOptimizer classes.\nhttps://github.com/Astro2024/Astro2024.github.io/blob/main/posts/logistic-regression/logistic.py\n Part A: Implement Logistic Regression \n LogisticRegression Class: \n Sigma:  In order to implement our Logistic Regression model I first started by defining a function called sigma. This function allows our gradient decent to find a global minimum for the loss function.\n\nimport torch\ndef sigma(self, val):\n        return 1 / (1 + torch.exp(-val))\n\n Loss:  After implementing the sigma function I created our loss function based off the equation\n\\(L(w) = \\frac{1}{n} \\sum_{i=1}^{n} [-y_i log(\\sigma(s_i)) - (1 - y_i)log(1 - \\sigma(s_i))]\\). Where our \\(s_i\\) is the predicted score at a given index and \\(\\sigma\\) is the function defined above.\n\ndef loss(self, X, y):\n        s = self.score(X)\n        inner = (-1*y*torch.log(self.sigma(s))) - ((1 - y) *torch.log(1- self.sigma(s)))\n        return (1/X.shape[0]) * inner.sum()\n\n Grad:  The last function we must define in the LogisticRegression class is “grad”. The mathematical equation for this function is \\(L(w) = \\frac{1}{n} \\sum_{i=1}^{n} (\\sigma(s_i) - y_i)x_i\\). In the code below we take advantage of linear algebra operation to eliminate explicit sum functions.\n\ndef grad(self, X, y):\n        s = self.score(X)\n        summation = (self.sigma(s) - y)@X\n        return (1/X.shape[0]) * summation\n\n GradientDescentOptimizer Class: \n Step:  This function computes one step of the Logistic Regression update using the feature matrix X and target vector y. The mathematical equation for the update is, \\(w_{k+1} \\leftarrow w_k - \\alpha \\triangledown L(w_K) + \\beta(w_k - w_{k-1})\\). Where \\(\\alpha\\) is our designated learning rate and \\(\\beta\\) is our momentum variable.\n\ndef step(self, X, y, alpha, beta):\n        temp = torch.clone(self.model.w)\n        new_w = alpha*self.model.grad(X,y) - beta*(self.model.w - self.model.w1)\n        self.model.w1 = temp\n        self.model.w -= new_w\n\n Part B: Experiments \nThe following block of code defines a function that generates random data we will use for data classification. Using this function we can choose the number of data point, how many dimensions each data point has, and how “noisy” the data is (how easily separable it is).\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(1234)\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise=.5)\n\n Vanilla Gradient Descent: \nThe following code is an example of why we use gradient descent optimization. Using 2 dimensional data, a sufficiently low alpha, and setting beta = 0 we can observe that our loss function is monotonically decreasing and looks like it is converging towards 0. This means as we do further iteration and optimization our loss will continue to get lower until it converges to a minimum loss.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss = 1.0\n# for keeping track of loss values\nloss_vec = []\n\nfor _ in range(500):\n    #Calculate loss and record improvement\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    #Update LR \n    opt.step(X, y, alpha = 0.1, beta = 0)\n\n#Plots the progress of our loss through optimization\nplt.plot(loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Logistic Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\n Benefits of Momentum: \nIn the example above we set our beta = 0 and saw that our loss function roughly followed a logarithmic curve. So what happens when we start to increase out beta value? Well, in not super technical terms we start to increase the “momentum” of the loss function. That is to say, by increasing beta it might take a little longer for the loss function to start decreasing, but once it does the rate of decrease is significantly higher. Below is an example of the use of the “beta” variable in the step function. Using the same data and learning rate we look at the difference between loss function with beta = 0 (no momentum) and one with beta= .8 (momentum). We can set that the function with momentum breaks our loss threshold (.05) in fewer iteration than the function with no momentum.\n\nX, y = classification_data(n_points=100, noise=.25, p_dims=10)\n#Initialize two Logistic Regression functions\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\nLR1 = LogisticRegression() \nopt1 = GradientDescentOptimizer(LR1)\n#Initialize lass for two functions\nloss = 1.0\nloss_vec = []\nloss1 = 1.0\nloss_vec1 = []\n\n#Iterate until the momentum model is under threshold\nwhile loss1 &gt; .05:\n    #Calculate and record losses\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n    loss1 = LR1.loss(X, y) \n    loss_vec1.append(loss1)\n\n    # Optimize model 1 with no momentum, and model 2 with momentum\n    opt.step(X, y, alpha = 0.05, beta = 0)\n    opt1.step(X, y, alpha = 0.05, beta = 0.8)\n\n#Plots the progress of our loss through optimization\nplt.plot(loss_vec, color = \"slategrey\", label=\"No Momentum\")\nplt.plot(loss_vec1, color = \"red\", label=\"Momentum\")\nplt.legend()\nlabs = plt.gca().set(xlabel = \"Logistic Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\n Overfitting: \nIn the code below we experience a phenomenon called overfitting. It is where we train the model so specifically and repetitively on a training set that it can no longer make accurate predictions about any data other than the training set. Using two sets of similar data where the dimensionality of our data is higher than the number of data points in our data set we first train a model on our training data. Since there are more dimensions than data points both the training and test data is linearly separable, however due to the high dimensionality, when we train the data our model only becomes able to predict the specific data in the training set. This is shown below. Even though the size of our data is relatively small due to high weight values and rounding errors, you can see that while the model is 100% accurate on the training data it is only 75% accurate on the testing data.\n\n#Initialize training and testing data\nX_train, y_train = classification_data(n_points=20, noise=.7, p_dims=25)\nX_test, y_test = classification_data(n_points=20, noise=.7, p_dims=25)\n\n#Initialize model\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss = 1.0\n# for keeping track of loss values\nloss_vec = []\nloss_vec_test = []\n\ncount = 0\nacc = 0\n\n#Iterate until 100% accuracy on training data or 500 iterations\nwhile acc &lt; 1 and count &lt; 500:\n    count +=1\n\n    #Calculate accuracy of model on training data\n    pred = LR.predict(X_train)\n    mcount = torch.sum(y_train == pred).item()\n    acc = mcount/len(pred)\n    \n    #Calculate and record loss of each model\n    loss = LR.loss(X_train, y_train) \n    loss_vec.append(loss)\n    loss1 = LR.loss(X_test, y_test) \n    loss_vec_test.append(loss1)\n\n    # Optimize on the training data\n    opt.step(X_train, y_train, alpha = 0.01, beta = 0.8)\n\n\n#Print the training accuracy\nprint(\"Training Accuracy: \" + str(acc))\npred = (torch.matmul(X_test, LR.w) &gt; 0).int()\nmcount = torch.sum(y_test == pred).item()\nperc = (mcount / len(pred))\nprint(\"Testing Accuracy: \" + str(perc))\n\n#Plots the progress of our loss through optimization\nplt.plot(loss_vec, color = \"slategrey\", label=\"Training Data\")\nplt.plot(loss_vec_test, color = \"red\", label=\"Testing Data\")\nplt.legend()\nlabs = plt.gca().set(xlabel = \"Logistic Iteration (Updates Only)\", ylabel = \"loss\")\n\nTraining Accuracy: 1.0\nTesting Accuracy: 0.75\n\n\n\n\n\n\n\n\n\n Conclusion: \nAbove we have implemented our logistic regression and gradient descent optimization classes so that we now have a working logistic regression model. With this implementation we have also explored how different forms of data and different parameters for our optimization can lead to various different results. For example, data with less noise is easier to minimize loss on and more likely to be linearly separable, momentum can be used in our optimization functions to decrease the number of iterations needed to converge on the “correct” weight vectors, and that even if the data is linearly separable, if our dimensionality is too high then we will induce overfitting on the training set and our models accuracy will decrease for outside data."
  },
  {
    "objectID": "posts/classifying-palmer-penguins/index.html",
    "href": "posts/classifying-palmer-penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\n\nAbstract\n\n\nIn this post I hope to explore the penguin data set and find a combination of variables that will give us the highest accurate rate when trying to predict the species of a penguin. I will start by cleaning up the data and exploring a few visual representation in order to gain insight into some of the most notable variables for species prediction. Then pairing those insights with an exhaustive search, I will find the most effective model(s) and graph their decision boundaries.\n\n#import libraries\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\n#Importing training data\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\n#Data Preparation\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\nl = LabelEncoder()\nl.fit(train[\"Island\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Sex\", \"Clutch Completion\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\ncolumns = []\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    columns.append(cols) \n\n\n#Additional data preperation for graphics\nd = train[train[\"Sex\"] != \".\"]\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    d[\"Species\"] = d[\"Species\"].str.split().str.get(0)\n    d[\"Islands\"] = l.transform(d[\"Island\"])\n\n\nThe following graphs are a combination of scatterplots exploring the effectiveness of stratifying the penguin population by Islands x random variable and collection of boxplots exploring the range of flipper length amongs the different species. The plots show that if any penguin is found on Torgersen it will be an Adelie. They also show Adelie and Gentoo are easily distinguishable using islands and most other variable, the most effective being Flipper Length. On the other hand, Chinstrap and Adelie are much harder to distinguish between, the variable Delta 13 C is probably the best variable for trying to differentiate between Chinstrap and Adelie. However, all around, the best variable to pair with Islands is the Culmen Length.\n\nimport seaborn as sns\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 10))\np1 = sns.scatterplot(d, x = \"Islands\", y = \"Delta 13 C (o/oo)\", hue = \"Species\", ax = ax[0,0])\np2 = sns.scatterplot(d, x = \"Islands\", y = \"Flipper Length (mm)\", hue = \"Species\", ax = ax[0,1])\np3 = sns.scatterplot(d, x = \"Islands\", y = \"Body Mass (g)\", hue = \"Species\", ax = ax[1,0])\np4 = sns.scatterplot(d, x = \"Islands\", y = \"Culmen Length (mm)\", hue = \"Species\", ax = ax[1,1])\n\np5 = sns.catplot(data=d, kind=\"bar\", x=\"Island\", y=\"Flipper Length (mm)\", hue=\"Species\")\np6 = sns.displot(d, x=\"Flipper Length (mm)\", col=\"Species\", row=\"Sex\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#Finds the best pairing of variables\nbest = ([], 0)\nfrom sklearn.exceptions import ConvergenceWarning\n\nfor x in columns:\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[x]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\n        if score &gt; best[1]:\n            best = (x, score)\n        elif score == best[1]:\n            print(x, score)\nprint(best[0], best[1])\n\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Culmen Depth (mm)'] 0.99609375\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)'] 0.99609375\n\n\n\nThe code above finds the best pairing of three variables. As there are two best pairing, in the code below we train two different models. One for the variables Culmen Length (mm), Culmen Depth (mm), and Sex. The other for Culmen Length (mm), Culmen Depth (mm), and Islands.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nX_test.head()\n\nLR1 = LogisticRegression()\nLR2 = LogisticRegression()\n\ncols1 = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_FEMALE', 'Sex_MALE',]\ncols2 = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n    mf1 = LR1.fit(X_train[cols1], y_train)\n    ms1 = LR1.score(X_test[cols1], y_test)\n    mf2 = LR2.fit(X_train[cols2], y_train)\n    ms2 = LR2.score(X_test[cols2], y_test)\n\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n#Plots the decision regions for our two model on the training data\nplot_regions(LR1, X_train[cols1], y_train)\nplot_regions(LR2, X_train[cols2], y_train)\n#Plots the decision regions for our two model on the testing data\nplot_regions(LR1, X_test[cols1], y_test)\nplot_regions(LR2, X_test[cols2], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred1 = LR1.predict(X_test[cols1])\ny_test_pred2 = LR2.predict(X_test[cols2])\nC1 = confusion_matrix(y_test, y_test_pred1)\nC2 = confusion_matrix(y_test, y_test_pred2)\nprint(C1, \"First Model\")\nprint(C2, \"Second Model\")\n\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]] First Model\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]] Second Model\n\n\n\nThere are no errors in either of the models on the dest data. However, looking at the training and test decision regions I would guess the most common errors come between Adelie and Gentoo predictions.\n\nDiscussion:\n\n\nIn this project I have explored a variety of variable combinations and founds two different combinations of three variables that are able to predict penguin species from a test set with a success rate of 100%. With only two variable, depending on which are chosen, it becomes easier to distinguish one of the species but the other two tend to be muddled. However, with the introduction of a third variable the two remaining species become easier to distinguish between. Using the combinations [Culmen Length (mm), Culmen Depth (mm), Sex] and [Culmen Length (mm), Culmen Depth (mm), Islands] we achieve the highest prediction accuracy for penguin species. On the training data we achieve a joint accuracy rate of 99.61% and a success rate of 100% on the test data."
  },
  {
    "objectID": "posts/optimal-descision-making/index.html",
    "href": "posts/optimal-descision-making/index.html",
    "title": "Optimal Descision Making",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\nIntroduction:\nThere are two main purposes of this blog post. The first is to explore score maximizing functions and how to choose “optimal” thresholds for a given function. We will do this by exploring trends present in the data, testing different parameters, and error-rates to improve out thresholds. The second purpose of this blog is to uncover and learn how automated decision systems might show bias towards certain sub-segments of a population. By assessing where bias might lie in our models we can better organize our date and parameters to mitigate “unfair” advantages or disadvantages present in the model for certain members of our test population.\n\nPart A:\n\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\nPart B:\n\n\n#Data Preparation\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df_train['person_home_ownership'])\nl = LabelEncoder()\nl.fit(df_train['loan_intent'])\nld = LabelEncoder()\nld.fit(df_train['loan_grade'])\n\ndef prepare_data(df):\n  df = df.dropna()\n  y = df['loan_status']\n  #df[\"home_ownership\"] = df[\"person_home_ownership\"]\n  #df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\nX_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\n...\nloan_intent_VENTURE\nloan_grade_A\nloan_grade_B\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0\n0.12\n6\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0\n0.27\n4\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n1\n0.05\n4\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0\n0.28\n10\nTrue\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n1\n0.25\n2\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n5 rows × 27 columns\n\n\n\n\n\nX_train[\"person_age\"].min()\n\n20\n\n\n\nimport seaborn as sns\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 10))\np1 = sns.scatterplot(df_train, x = \"person_age\", y = \"person_income\", hue = \"loan_status\", ax = ax[0,0])\np2 = sns.scatterplot(df_train, x = \"loan_intent\", y = \"person_emp_length\", hue = \"loan_status\", ax = ax[0,1])\np3 = sns.scatterplot(df_train, x = \"loan_amnt\", y = \"loan_int_rate\", hue = \"loan_status\", ax = ax[1,0])\np4 = sns.scatterplot(df_train, x = \"loan_percent_income\", y = \"cb_person_cred_hist_length\", hue = \"loan_status\", ax = ax[1,1])\n\np5 = sns.catplot(data=df_train, kind=\"bar\", x=\"person_home_ownership\", y=\"loan_amnt\", hue=\"loan_status\")\n#p6 = sns.displot(df_train, x=\"loan_int_rate\", col=\"loan_status\", row=\"person_home_ownership\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart C:\n\n\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\nall_quant_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\ncolumns = []\nfor qual in combinations(all_qual_cols, 1): \n  qual_cols1 = [col for col in X_train.columns if qual[0] in col ]\n  #qual_cols2 = [col for col in X_train.columns if qual[1] in col ]\n  #qual_cols3 = [col for col in X_train.columns if qual[2] in col ]\n  for pair in combinations(all_quant_cols, 1):\n    cols = qual_cols1 + list(pair) \n    #cols = qual_cols1 + qual_cols2 + list(pair) \n    #cols = qual_cols1 + qual_cols2 + qual_cols3 + list(pair) \n    columns.append(cols) \n#Finds the best pairing of variables\nbest1 = ([], 0)\nbest2 = ([], 0)\nfrom sklearn.exceptions import ConvergenceWarning\n\nfor x in columns:\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[x]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\n        if score &gt; best1[1]:\n            best2 = best1\n            best1 = (x, score)\n        elif score == best1[1]:\n            print(x, score)\nprint(best1[1], best1[0])\nprint(best2[1], best2[0])\n\n0.8492600515126381 ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_percent_income']\n0.817217444449295 ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_int_rate']\n\n\n\nbest_vars = ['person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT', 'loan_percent_income']\nwith warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        X_train1 = X_train[best_vars]\n        LR = LogisticRegression()\n        m = LR.fit(X_train1, y_train)\n        score = LR.score(X_train1, y_train)\nweights = LR.coef_\nweights\n\narray([[-0.76352014, -0.10753429, -1.80005286,  0.27250832,  8.27561064]])\n\n\n\ndef linear_score(df, w, x):\n    sum = 0\n    for i in range(len(x)):\n        sum += w[0][i]*df[x[i]]\n    return sum\nlscores = linear_score(X_train, weights, best_vars)\nhist = plt.hist(lscores)\n\n\n\n\n\n\n\n\n\ndef predict(score_fun, w, x, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(df, w, x)\n    return 1*(scores &gt; threshold)\n\n\nPart D:\n\n\nacc = []\nfor t in np.linspace(lscores.min()-.01, lscores.max()+.01, 101):\n    y_pred = lscores &gt;= t\n    ac = (y_pred == y_train).mean()\n    acc = acc + [(y_pred == y_train).mean()]\n    print(f\"A threshold of {t:.2f} gives an accuracy of {ac:.3f}.\")\n#2.6 - 2.8 best threshold for accuracy\n\nA threshold of -1.73 gives an accuracy of 0.215.\nA threshold of -1.64 gives an accuracy of 0.215.\nA threshold of -1.56 gives an accuracy of 0.216.\nA threshold of -1.48 gives an accuracy of 0.218.\nA threshold of -1.39 gives an accuracy of 0.220.\nA threshold of -1.31 gives an accuracy of 0.223.\nA threshold of -1.22 gives an accuracy of 0.225.\nA threshold of -1.14 gives an accuracy of 0.228.\nA threshold of -1.06 gives an accuracy of 0.230.\nA threshold of -0.97 gives an accuracy of 0.233.\nA threshold of -0.89 gives an accuracy of 0.239.\nA threshold of -0.81 gives an accuracy of 0.242.\nA threshold of -0.72 gives an accuracy of 0.245.\nA threshold of -0.64 gives an accuracy of 0.250.\nA threshold of -0.55 gives an accuracy of 0.258.\nA threshold of -0.47 gives an accuracy of 0.271.\nA threshold of -0.39 gives an accuracy of 0.286.\nA threshold of -0.30 gives an accuracy of 0.305.\nA threshold of -0.22 gives an accuracy of 0.323.\nA threshold of -0.13 gives an accuracy of 0.342.\nA threshold of -0.05 gives an accuracy of 0.359.\nA threshold of 0.03 gives an accuracy of 0.375.\nA threshold of 0.12 gives an accuracy of 0.392.\nA threshold of 0.20 gives an accuracy of 0.409.\nA threshold of 0.28 gives an accuracy of 0.425.\nA threshold of 0.37 gives an accuracy of 0.443.\nA threshold of 0.45 gives an accuracy of 0.459.\nA threshold of 0.54 gives an accuracy of 0.482.\nA threshold of 0.62 gives an accuracy of 0.502.\nA threshold of 0.70 gives an accuracy of 0.525.\nA threshold of 0.79 gives an accuracy of 0.545.\nA threshold of 0.87 gives an accuracy of 0.568.\nA threshold of 0.95 gives an accuracy of 0.592.\nA threshold of 1.04 gives an accuracy of 0.614.\nA threshold of 1.12 gives an accuracy of 0.637.\nA threshold of 1.21 gives an accuracy of 0.657.\nA threshold of 1.29 gives an accuracy of 0.679.\nA threshold of 1.37 gives an accuracy of 0.701.\nA threshold of 1.46 gives an accuracy of 0.717.\nA threshold of 1.54 gives an accuracy of 0.733.\nA threshold of 1.63 gives an accuracy of 0.745.\nA threshold of 1.71 gives an accuracy of 0.759.\nA threshold of 1.79 gives an accuracy of 0.770.\nA threshold of 1.88 gives an accuracy of 0.781.\nA threshold of 1.96 gives an accuracy of 0.794.\nA threshold of 2.04 gives an accuracy of 0.805.\nA threshold of 2.13 gives an accuracy of 0.812.\nA threshold of 2.21 gives an accuracy of 0.821.\nA threshold of 2.30 gives an accuracy of 0.827.\nA threshold of 2.38 gives an accuracy of 0.835.\nA threshold of 2.46 gives an accuracy of 0.838.\nA threshold of 2.55 gives an accuracy of 0.843.\nA threshold of 2.63 gives an accuracy of 0.846.\nA threshold of 2.72 gives an accuracy of 0.849.\nA threshold of 2.80 gives an accuracy of 0.853.\nA threshold of 2.88 gives an accuracy of 0.847.\nA threshold of 2.97 gives an accuracy of 0.841.\nA threshold of 3.05 gives an accuracy of 0.834.\nA threshold of 3.13 gives an accuracy of 0.829.\nA threshold of 3.22 gives an accuracy of 0.825.\nA threshold of 3.30 gives an accuracy of 0.820.\nA threshold of 3.39 gives an accuracy of 0.818.\nA threshold of 3.47 gives an accuracy of 0.814.\nA threshold of 3.55 gives an accuracy of 0.811.\nA threshold of 3.64 gives an accuracy of 0.806.\nA threshold of 3.72 gives an accuracy of 0.804.\nA threshold of 3.80 gives an accuracy of 0.801.\nA threshold of 3.89 gives an accuracy of 0.799.\nA threshold of 3.97 gives an accuracy of 0.797.\nA threshold of 4.06 gives an accuracy of 0.796.\nA threshold of 4.14 gives an accuracy of 0.795.\nA threshold of 4.22 gives an accuracy of 0.793.\nA threshold of 4.31 gives an accuracy of 0.792.\nA threshold of 4.39 gives an accuracy of 0.791.\nA threshold of 4.48 gives an accuracy of 0.790.\nA threshold of 4.56 gives an accuracy of 0.789.\nA threshold of 4.64 gives an accuracy of 0.788.\nA threshold of 4.73 gives an accuracy of 0.788.\nA threshold of 4.81 gives an accuracy of 0.787.\nA threshold of 4.89 gives an accuracy of 0.787.\nA threshold of 4.98 gives an accuracy of 0.787.\nA threshold of 5.06 gives an accuracy of 0.787.\nA threshold of 5.15 gives an accuracy of 0.787.\nA threshold of 5.23 gives an accuracy of 0.786.\nA threshold of 5.31 gives an accuracy of 0.786.\nA threshold of 5.40 gives an accuracy of 0.786.\nA threshold of 5.48 gives an accuracy of 0.786.\nA threshold of 5.57 gives an accuracy of 0.786.\nA threshold of 5.65 gives an accuracy of 0.785.\nA threshold of 5.73 gives an accuracy of 0.785.\nA threshold of 5.82 gives an accuracy of 0.785.\nA threshold of 5.90 gives an accuracy of 0.785.\nA threshold of 5.98 gives an accuracy of 0.785.\nA threshold of 6.07 gives an accuracy of 0.785.\nA threshold of 6.15 gives an accuracy of 0.785.\nA threshold of 6.24 gives an accuracy of 0.785.\nA threshold of 6.32 gives an accuracy of 0.785.\nA threshold of 6.40 gives an accuracy of 0.785.\nA threshold of 6.49 gives an accuracy of 0.785.\nA threshold of 6.57 gives an accuracy of 0.785.\nA threshold of 6.65 gives an accuracy of 0.785.\n\n\n\nfrom sklearn.metrics import confusion_matrix\nfig, ax = plt.subplots(1, 1, figsize = (6, 4))\n\nnum_thresholds = 101\n\nFPR = np.zeros(num_thresholds)\nTPR = np.zeros(num_thresholds)\nconfusions = []\nT = np.linspace(lscores.min()-0.1, lscores.max()+0.1, num_thresholds)\ns = linear_score(X_train, weights, best_vars)\n\nfor i in range(num_thresholds):\n    t = T[i]\n    preds = s &gt;= t\n    FPR[i] = ((preds == 1) & (y_train == 0)).sum() / (y_train == 0).sum()\n    TPR[i] = ((preds == 1) & (y_train == 1)).sum() / (y_train == 1).sum()\n    confusions.append(confusion_matrix(y_train, preds))\n\n\nax.plot(FPR, TPR, color = \"black\")\nax.plot([0,1], [0,1], linestyle=\"--\", color = \"grey\")\nax.set_aspect('equal')\n\nlabs = ax.set(xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", title = \"ROC Curve\")\n\n\n\n\n\n\n\n\n\nX_train[\"bank_profit_repaid\"] = X_train[\"loan_amnt\"]*(1 + 0.25*(X_train[\"loan_int_rate\"]/100))**10 - X_train[\"loan_amnt\"]\nX_train[\"bank_profit_default\"] = X_train[\"loan_amnt\"]*(1 + 0.25*(X_train[\"loan_int_rate\"]/100))**3 - 1.7*X_train[\"loan_amnt\"]\n\n\ngood_choice = []\nbad_choice = []\nprob_0 = (confusions[1][0][0]+confusions[1][0][1])/confusions[1].sum()\nprob_1 = (confusions[1][1][0]+confusions[1][1][1])/confusions[1].sum()\nfor x in confusions:\n    good_choice.append(float(x[0][0]))\n    bad_choice.append(float(x[1][0]))\n\n\nTNR = 1 - FPR\nFNR = 1 - TPR\n\ncost_of_FN = X_train[\"bank_profit_default\"]\ngain_of_TN = X_train[\"bank_profit_repaid\"]\n#This has the same maximum as the equation below, however it does not show the E[] per loan\n#gain =  gain_of_TN.mean()*np.array(good_choice)  + cost_of_FN.mean()*np.array(bad_choice)\n\n# I was looking at the fourth set of notes from class and was confused at the equation we were using to calculate gain.\n# It did not seem to give us any useful information gain, so I figured there might be an error. I look online and found\n# a gain equation that was what was mentioned in class but now normalized (https://medium.com/@overfittedcat/expected-value-as-evaluation-metric-in-machine-learning-b3836511cd)\ngain = prob_0*(gain_of_TN.mean() * TNR) + prob_1*(cost_of_FN.mean() * FNR)\n\n# Gain function from notes\n#gain = (gain_of_TN.mean() * TNR) + (cost_of_FN.mean() * FNR)\n\nplt.plot(T, gain)\n\n#The following function I found online for annotating the maximum point\ndef annot_max(x,y, ax=None):\n    xmax = x[np.argmax(y)]\n    ymax = y.max()\n    text= \"x={:.3f}, y={:.3f}\".format(xmax, ymax)\n    if not ax:\n        ax=plt.gca()\n    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n    arrowprops=dict(arrowstyle=\"-&gt;\",connectionstyle=\"angle,angleA=0,angleB=60\")\n    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.96), **kw)\n\nannot_max(T,gain)\nplt.gca().set(ylim = (-300, 2000), xlim = (-2, 7))\nlabs = plt.gca().set(xlabel = r\"Threshold $t$\", ylabel = \"Expected profit per loan\")\n\n\n\n\n\n\n\n\n\nplt.plot(T, acc)\nannot_max(T, np.array(acc))\nplt.gca().set(ylim = (0, 1), xlim = (-2, 7))\nlabs = plt.gca().set(xlabel = r\"Threshold $t$\", ylabel = \"Accuracy\")\n\n\n\n\n\n\n\n\nIn this section I created a gain function using the average gain on a fully repaid loan and the average loss on a defaulted loan. After examining the expected gain function we were given in class, I felt like it did not provide us with any substantial information gain, so I researched expected value functions and found a version of the in-class function that was normalized. The two graphs above show the optimal threshold for accuracy and expected profit per loan. For both the maximizing threshold was 2.806 and it brought our accuracy up to 85.3% and our expected profit per loan to $1614.14.\n\nPart: E\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\nX_test, y_test = prepare_data(df_test)\n\nX_test[\"bank_profit_repaid\"] = X_test[\"loan_amnt\"]*(1 + 0.25*(X_test[\"loan_int_rate\"]/100))**10 - X_test[\"loan_amnt\"]\nX_test[\"bank_profit_default\"] = X_test[\"loan_amnt\"]*(1 + 0.25*(X_test[\"loan_int_rate\"]/100))**3 - 1.7*X_test[\"loan_amnt\"]\n\n\n\ny_predicted = predict(linear_score, weights, best_vars, 2.806, X_test)\ndf_test[\"test_predicted\"] = y_predicted\ninvert = (y_predicted + 1) % 2\n\ngaint = (X_test[\"bank_profit_default\"] * y_predicted) + (X_test[\"bank_profit_repaid\"] * invert)\nprint(gaint.mean())\n\nFPR1   = ((y_predicted == 1) & (y_test == 0)).sum() / (y_test == 0).sum()\nTPR1   = ((y_predicted == 1) & (y_test == 1)).sum() / (y_test == 1).sum()\n\nTNR1 = 1 - FPR1\nFNR1 = 1 - TPR1\n\nconfuse = confusion_matrix(y_test, y_predicted)\n\nprob_zero = (confuse[0][0]+confuse[0][1])/confuse.sum()\nprob_one = (confuse[1][0]+confuse[1][1])/confuse.sum()\n\ngain_test = prob_zero*(X_test[\"bank_profit_repaid\"].mean() * TNR1) + prob_one*(X_test[\"bank_profit_default\"].mean() * FNR1)\ngain_test\n\n1966.832456892238\n\n\n1605.4481388536585\n\n\n\n1 - 1605.448/1614.137 \n\n0.005383062280339135\n\n\nThe expected gain for the test data set is very close to our train data set. The training set was 1614.137 and our test set is 1605.448. That is only a $8.69 difference. From the banks perspective the weights and threshold we selected were only .5% off which is pretty good.\n\nPart F:\n\n#sns.catplot(data=df_test, kind=\"bar\", x=\"person_age\", y=\"test_predicted\")\n#sns.scatterplot(df_test, x = \"person_age\", y = \"test_predicted\")\n\ntr = df_test.groupby(\"person_age\").aggregate(\"test_predicted\").mean()\nsns.scatterplot(tr)\n\n\n\n\n\n\n\n\n\n\n\nintent_predicted = df_test.groupby(\"loan_intent\").aggregate(\"test_predicted\").mean()\nintent_real = df_test.groupby(\"loan_intent\").aggregate(\"loan_status\").mean()\nprint(intent_predicted)\nprint(intent_real)\n\nloan_intent\nDEBTCONSOLIDATION    0.095133\nEDUCATION            0.075680\nHOMEIMPROVEMENT      0.037338\nMEDICAL              0.102516\nPERSONAL             0.087174\nVENTURE              0.079876\nName: test_predicted, dtype: float64\nloan_intent\nDEBTCONSOLIDATION    0.279497\nEDUCATION            0.167421\nHOMEIMPROVEMENT      0.246088\nMEDICAL              0.281553\nPERSONAL             0.219227\nVENTURE              0.145701\nName: loan_status, dtype: float64\n\n\n\nprint(\"mean\", df_test.groupby(\"test_predicted\").aggregate(\"person_income\").mean())\nprint(\"median\", df_test.groupby(\"test_predicted\").aggregate(\"person_income\").median())\n\nmean test_predicted\n0.0    69033.762122\n1.0    39483.673729\nName: person_income, dtype: float64\nmedian test_predicted\n0.0    58700.0\n1.0    36000.0\nName: person_income, dtype: float64\n\n\n\nIs it more difficult for people in certain age groups to access credit under your proposed system?\n\nFor the most part as you get older the more likely you are to get access to credit\n\nIs it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\n\nCompared to other intents, medical loans are predicted to be the most likely to default under my model. In the actual data medical loans also have the highest default rate. Across the board my model is more lenient when it comes to loan default prediction.\n\nHow does a person’s income level impact the ease with which they can access credit under your decision system?\n\nThe lower someone’s income the more likely they are to be predicted to default.\n\n\n\nPart G:\nConclusion:\nAt the start of this blog I set out to accomplish two main goals. The first was to explore score maximizing functions and how to choose “optimal” thresholds for a given function. The second was to uncover and learn how automated decision systems might show bias towards certain sub-segments of a population. Now that we have arrived at the concluding part of the assignment I can happily say I have completed both of my goals.\nIn this blog I looked to define an automated decision system for a hypothetical bank extending credit and worked to predict the expected profit said bank using a variety of different parameters with a score function and a threshold. Through all my testing I would that the “optimal” parameters and threshold for expected profits were the catagories;‘person_home_ownership_MORTGAGE’, ‘person_home_ownership_OTHER’, ‘person_home_ownership_OWN’, ‘person_home_ownership_RENT’, and ‘loan_percent_income’ paired with a threshold of 2.806. Using these two values the expected average profit per loan for the bank was $1614.137.\nAfter maximizing my expected return function and threshold, I looked through my results to answer my second question: Is/Where is there bias in my automated decision system, who does it affect and how? The answer to the first part is, yes, there is definitely bias in my model. It is easier to get a loan the older and richer you are, and depending on what you are trying to get a loan for you will have a more difficult time getting a loan. Now, I do want to briefly preface the following comments by noting, although my model shows a bias towards certain types of loan intent, across the board my model is much more lenient in its prediction of default than the actual rates (I am not commenting on if this is good or bad). The hardest type of loan to be approved for is medical loans because they tend to have the highest default rate. I would love to explore the cause of this further because I imagine a pretty strong correlation between needing a medical loan and having a lower income. So independent of income how skewed is the data? Also, is it possible that the reason people default on medical loans on average at a higher rate because the more expensive operations have a higher mortality rate and thus people cannot pay back the loan? If this conjecture is true then is it truly fair to make it more difficult for people to get medical loans based on other peoples death? I’d wager that the longer someone has to wait for a surgery due to insufficient funds the higher their own risk of death is. On the other hand, should a bank be the one forced to take on the extra financial risk of a sick/hurt person or should the insurance/medical/governmental systems bare more of the financial burden? Personally, I think the current system places and undeserved burden both on the patient and financial institution. I would love to participate in further analysis on this topic to help answer these questions."
  },
  {
    "objectID": "posts/recreating-compas/index.html",
    "href": "posts/recreating-compas/index.html",
    "title": "Replication Study",
    "section": "",
    "text": "%load_ext autoreload %autoreload 2\n\nAbstract\n\nIn the following code we will work to replicate various figures from the Dissecting racial bias in an algorithm used to manage the health of populations and use data analysis to try and validate some of the studies results. The first graphic we will reproduce will break down the relationship a predicted risk score has with # of chronic illness for a given gender and race. This graph will give us insight into whether the risk algorithm has any biases for a given race or gender. The second graphic we will recreate is a comparison of medical expenditure and risk scores/ number of chronic illnesses between black and white patients. Using these graphs we will ascertain whether or not there exists a price disparity between races and in the final section we will quantify how large of a disparity there may or may not be.\n\nPart A: Data Access\n\n#Import necessary libraries and downloads our data set\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf.head()\n\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\n\n\nPart B: Reproduce Fig. 1\n\n#Separates our data set into male and female patients\nmen = df[df[\"dem_female\"] == 0]\nwomen = df[df[\"dem_female\"] == 1]\n\n\n#Normalizes the risk scores for both men and women into percentile risk\nmen[\"percentile risk\"] = men[\"risk_score_t\"].rank(pct = True) * 100\nmen[\"percentile risk\"] = men[\"percentile risk\"].round()\nwomen[\"percentile risk\"] = women[\"risk_score_t\"].rank(pct = True) * 100\nwomen[\"percentile risk\"] = women[\"percentile risk\"].round()\n\n/var/folders/bh/dckst2q54p57m_p499z1mdz80000gn/T/ipykernel_38310/707116237.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  men[\"percentile risk\"] = men[\"risk_score_t\"].rank(pct = True) * 100\n/var/folders/bh/dckst2q54p57m_p499z1mdz80000gn/T/ipykernel_38310/707116237.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  men[\"percentile risk\"] = men[\"percentile risk\"].round()\n/var/folders/bh/dckst2q54p57m_p499z1mdz80000gn/T/ipykernel_38310/707116237.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  women[\"percentile risk\"] = women[\"risk_score_t\"].rank(pct = True) * 100\n/var/folders/bh/dckst2q54p57m_p499z1mdz80000gn/T/ipykernel_38310/707116237.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  women[\"percentile risk\"] = women[\"percentile risk\"].round()\n\n\n\n#Groups our data by percentile risk and race, then finds the mean number of chronic illnesses\nmale_data = men.groupby([\"percentile risk\", \"race\"]).aggregate({\"gagne_sum_t\" : \"mean\"})\nfemale_data = women.groupby([\"percentile risk\", \"race\"]).aggregate({\"gagne_sum_t\" : \"mean\"})\n\n#Plots our data\nfig, ax = plt.subplots(1,2, figsize = (15, 5))\np1 = sns.scatterplot(data=male_data, y = \"percentile risk\", x = \"gagne_sum_t\", hue=\"race\", ax=ax[0])\np1.set(xlabel =\"Mean Number of Chronic Illnesses\", ylabel = \"Percentile Risk Score\", title ='Male')\np2 = sns.scatterplot(data=female_data, y = \"percentile risk\", x = \"gagne_sum_t\", hue=\"race\", ax=ax[1])\np2.set(xlabel =\"Mean Number of Chronic Illnesses\", ylabel = \"Percentile Risk Score\", title ='Female')\n\n[Text(0.5, 0, 'Mean Number of Chronic Illnesses'),\n Text(0, 0.5, 'Percentile Risk Score'),\n Text(0.5, 1.0, 'Female')]\n\n\n\n\n\n\n\n\n\nSuppose that Patient A is Black, that Patient B is White, and that both Patient A and Patient B have exactly the same chronic illnesses. Are Patient A and Patient B equally likely to be referred to the high-risk care management program?\n\nNo, on average patient B, the white patient is more likely to be referred to a high-risk care management program. The disparity between risk scores is most apparent in the lower numbers of chronic illnesses where white patients are in a significantly higher risk percentile. However, as the mean number of chronic illnesses increases the disparity in percentile risk scores decreases.\n\n\nPart C: Reproduce Fig. 3\n\n\n#Normalizes the risk scores into percentile risk\ndf[\"percentile risk\"] = df[\"risk_score_t\"].rank(pct = True) * 100\ndf[\"percentile risk\"] = df[\"percentile risk\"].round()\n\n#Groups our data by percentile risk and race, then finds the mean expenditure\ndata = df.groupby([\"percentile risk\", \"race\"]).aggregate({\"cost_t\" : \"mean\"})\n#Groups our data by total number of chronic illnesses and race, then finds the mean expenditure\ndata1 = df.groupby([\"gagne_sum_t\", \"race\"]).aggregate({\"cost_t\" : \"mean\"})\n\n#Plots our data\nfig, ax = plt.subplots(1,2, figsize = (15, 5), sharey = True,)\np3 = sns.scatterplot(data=data, x = \"percentile risk\", y = \"cost_t\", hue=\"race\", ax=ax[0])\np3.set(ylabel =\"Total Medical Expenditure\", xlabel = \"Percentile Risk Score\", yscale=\"log\")\np4 = sns.scatterplot(data=data1, x = \"gagne_sum_t\", y = \"cost_t\", hue=\"race\", ax=ax[1])\np4.set(ylabel =\"\", xlabel = \"Number of Chronic Illnesses\")\n\n\n\n\n\n\n\n\nIt seems like on average black patients have lower medical expenditure that their white counterparts with in a given risk score percentile. However, it seems like as you approach the extreme ends of our decile, the disparity shrinks. The chart on the right is a little more confusing. It seems logical that as you have more chronic illnesses you will have higher medical expenditures, however, after around 13 chronic illnesses it seems like the cost goes down. I wonder whether this is cause by a lack of data on the tail end so our data is slightly skewed by a few individuals. Also, it seems like much of the medical expenditure disparities that we see in the first chart are not present when we compare the cost to # of chronic illnesses.\n\nPart D: Modeling Cost Disparity\nData Preparation:\n\n# Percent of people in data set with &lt; 6 chronic illnesses\nperc_less_six = df[df[\"gagne_sum_t\"] &lt; 6].shape[0] / df.shape[0]\nperc_six_data = df[df[\"gagne_sum_t\"] &lt; 6]\n#Creates a new column of the data set which is just the logarithm of the cost\nperc_six_data = perc_six_data[perc_six_data[\"cost_t\"] &gt; 0]\nperc_six_data[\"log_price\"] = np.log(perc_six_data[\"cost_t\"])\n# Creates a column for the qualitative race variable: 0 = white, 1 = Black.\nperc_six_data[\"quant_race\"] = pd.get_dummies(perc_six_data[\"race\"])[\"black\"]\nperc_six_data[\"quant_race\"].value_counts()\n#Separate data into predictor variables [race, # chronic conditions], target variable y (the log-cost)\nX_train = perc_six_data[[\"quant_race\", \"gagne_sum_t\"]]\ny_train = perc_six_data[\"log_price\"]\n\nModeling:\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n# Constructs data sets with polynomial features of various size\ndef add_polynomial_features(X, degree):\n  X_ = X.copy()\n  for j in range(1, degree):\n    X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n  return X_\n\n#Shows degree 6 is best, everything after does just as well however the higher the degree the more complex the math will become\nfor i in range(10):\n  temp = add_polynomial_features(X_train, i)\n  LR = LinearRegression()\n  cv_scores_LR = cross_val_score(LR, temp, y_train, cv=5)\n  print(cv_scores_LR)\n\n[0.07906298 0.0841587  0.08868864 0.0881431  0.08709964]\n[0.07906298 0.0841587  0.08868864 0.0881431  0.08709964]\n[0.07906298 0.0841587  0.08868864 0.0881431  0.08709964]\n[0.08029865 0.08498736 0.08879388 0.08907137 0.0879535 ]\n[0.08075755 0.08488526 0.08963978 0.09065718 0.08911137]\n[0.08113733 0.08565834 0.08984305 0.0906711  0.08953255]\n[0.0813977  0.08622709 0.08987886 0.09135492 0.08991925]\n[0.0813977  0.08622709 0.08987886 0.09135492 0.08991925]\n[0.0813977  0.08622709 0.08987886 0.09135492 0.08991925]\n[0.0813977  0.08622709 0.08987886 0.09135492 0.08991925]\n\n\n\nLR = LinearRegression()\nLR.fit(add_polynomial_features(X_train, 6), y_train)\nprint(\"Incurred costs for Black patients are\", np.exp(LR.coef_)[0]*100, \"percent of their white counterparts\")\n\nIncurred costs for Black patients are 75.3732233163919 percent of their white counterparts\n\n\nThis finding by itself does not prove Obermeyer’s entire paper, however it does support his claim “that we spend less money caring for Black patients than for white patients”. The analysis performed above does not prove or speak to whether this disparity is caused by unequal access or whether the algorithm actually predicts health care cost rather than illness.\n\nPart E: Discussion\nIn this blog post we have successfully recreated figure one and three of Obermeyer’s study and have discovered two main findings. First, for two patients, one who is black and the other who is white, to have similar risk scores, the black patient on average much have a significantly higher number of chronic illnesses than their white counterpart. The second main finding of our analysis is that their is a financial disparity between black and white patients with in a certain risk bracket. The incurred costs for Black patients is 75.4% of their white counterparts. The author of the paper we are replicating claims this is due to unequal access to care and using external knowledge I am inclined to agree with him. However, for the sake of recreating his findings, we must clarify that we did not find any link in our data that would back up this claim (this is not saying it is a false claim, but rather it is a disclaimer).\nThe algorithm does not seem to satisfy independence since as we stated above black patients on average much have a significantly higher number of chronic illnesses than their white counterpart. We do not really explore the other two standards, separation and sufficiency, in this blog post however if we had to give a prediction, we would conjecture to say separation is not satisfied, but sufficiency is, since it is more defined by the creators of the algorithm."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html",
    "href": "posts/implementing-perceptron/index.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n Abstract \nIn this blog post we will be exploring the implementations of the perceptron algorithm and examining a variety of different examples of its uses. We will start by exploring its capability of classifying linearly separable data in 2 dimensions and then we will see how it behaves on not linearly separable and higher dimensional data using single step optimization loops. After that we will implement and use a minibatch optimization loop and compare its results to the single step examples.\nI have attached below a link to my source code for the Perceptron class. In the gradient class I implemented conditional statements to check whether we are trying to use a single or minibatch step. Inside each conditional we calculate the score and then check to see how effective our weights are and which predictions were wrong. Then for the wrong scores we multiply against our feature matrix to create the gradient. In the case of a minibatch we then take the average gradient and multiply it by our leaning rate.\nhttps://github.com/Astro2024/Astro2024.github.io/blob/main/posts/implementing-perceptron/perceptron.py\n Part A: Implementing Perceptron \nThe following code imports the necessary libraries and define the functions we will be continually be using throughout this blog post.\n\n#Import Libraries\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n#Set seed for consistent results\ntorch.manual_seed(1234)\n\n#This function creates our randomized data we are trying to classify\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\n#This function plots our data cleanly\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nX, y = perceptron_data()\n\n#This function plots the weights and decision boundaries\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\n\n Part B: Experiments \nWhen our data is linearly separable since the perceptron algorithm converges we can use the weight vector to describe a separating line\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n# for keeping track of loss values\nloss_vec = []\n\nwhile loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n\n    #Take a random x and y pair to optimize on\n    i = torch.randint(X.size()[0], size = (1,))\n    X_ = X[[i],:]\n    y_ = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(X_, y_)\n\n#Plots the progress of our loss through optimization\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n#Plots the final \"optimal\" weight vector\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen using 2 dimensional non-linearly separable data the perceptron algorithm does not settle on a final value of W (the weight vector won’t converge), but will instead run until the maximum number of iterations is reached, without ever achieving perfect accuracy.\n\n#Initialize not linearly separable data\nX, y = perceptron_data(300, .5)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\ncount = 0\n# for keeping track of loss values\nloss_vec = []\n\nwhile count &lt; 1000 and loss &gt; 0: # Now only goes for 1000 steps or if the loss hits 0 (won't happen)\n    count += 1\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n\n    #Take a random x and y pair to optimize on\n    i = torch.randint(X.size()[0], size = (1,))\n    X_ = X[[i],:]\n    y_ = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(X_, y_)\n\n#Plots the progress of our loss through optimization\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n#Plots the final \"optimal\" weight vector\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur perceptron algorithm is also able to work in more than 2 dimensions! Below is an example of running your algorithm on data with 5 features. You will notice that I have not attached a graph with a decision boundary. This is because it is incredible difficult to graph in 5 dimensions. However, if we just pay attention to the graph of the loss over time, you can see that almost immediately our loss goes down to near 0. From this we can infer that our perceptron algorithm has optimized a nearly accurate weight vector.\n\n#Initialize 5 dimensional data\nX, y = perceptron_data(300, .3, 5)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\ncount = 0\n# for keeping track of loss values\nloss_vec = []\n\nwhile count &lt; 300 and loss &gt; 0: # Now only goes for 300 steps or if the loss hits 0 (won't happen)\n    count += 1\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    i = torch.randint(X.size()[0], size = (1,))\n\n    X_ = X[[i],:]\n    y_ = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(X_, y_)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\n Part C: Minibatch Perceptron \nIn the following 3 examples we will examine how the optimization performs when, rather than using a singular randomized point to “step”, we use a random minibatch of data points.\nIn this first example we will examine a batch size of k = 1. At this size the minibatch perceptron performs similarly to regular perceptron.\n\nX, y = perceptron_data(300, .3, 2)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\ncount = 0\n# for keeping track of loss values\nloss_vec = []\n\nwhile count &lt; 1000 and loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    count += 1\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    #Creates our random minibatch\n    k = 1\n    ix = torch.randperm(X.size(0))[:k]\n    X_ = X[ix,:]\n    y_ = y[ix]\n    \n    # perform a perceptron update using the random data points\n    opt.step(X_, y_)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor our second example we will explore a larger minbatch (when k = 10) and show that the minibatch perceptron can still find a separating line in 2 dimensions\n\nX, y = perceptron_data(300, .3, 2)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\ncount = 0\n# for keeping track of loss values\nloss_vec = []\n\nwhile count &lt; 1000 and loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    count += 1\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    #Initialize minibatch of 10 data points\n    k = 10\n    ix = torch.randperm(X.size(0))[:k]\n    X_ = X[ix,:]\n    y_ = y[ix]\n    \n    # perform a perceptron update using the random data point\n    opt.step(X_, y_)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor our third and last example we will examine what happens with a minibatch of size k = n (that is, the batch size is the size of the entire data set). We will show that the minibatch perceptron can converge even when the data is not linearly separable, provided that the learning rate is small enough. In order to dictate the learning rate I added an additional optional parameter to our step and gradient functions. By default, this parameter, “alpha”, is set to 1. However, for a batch size this large I have set alpha = .01.\nYou can see that in our loss graph the loss converges to between 10% and 15%\n\n#Initialize not linearly separable data\nX, y = perceptron_data(300, .6, 2)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\ncount = 0\n# for keeping track of loss values\nloss_vec = []\n\nwhile count &lt; 1000 and loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    count += 1\n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    #takes entire X and y\n    ix = torch.randperm(X.size(0))\n    X_ = X[ix,:]\n    y_ = y[ix]\n    \n    # perform a perceptron update using the random data points and sets learning rate to .01\n    opt.step(X_, y_, .01)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Part D: Writing \nThe runtime of a single iteration of the perceptron algorithm large depends on the time complexity of linear algebraic computations. If X is an NxM matrix and y is Mx1 then the time complexity of X@y is approximately O(2NM), so our score function is O(2NM). Every time we call loss we also call score and get a Nx1 matrix that we multiply through (O(N)), switch to boolean (O(N)), and then we switch back to int and take the mean (O(2N)), so the time complexity of loss is O(2NM) + O(4N). I am going to ignore trying to calculate the time complexity of getting the random data point because the indexing of an array is just O(1) and so it all relies on the complexity of our random function. The last complexity we need to examine is for our step function, which since it contains simple addition and a call to grad we are only concerned with the complexity of grad. If we are looking at a single data point the complexity of grad is O(3M). However, if we are looking at a minibatch of size k, then the complexity is O(2kM + 2k + 2k + 2kM + kM). So, in conclusion a single iteration of the perceptron algorithm is O(2NM + 4N + 3M) = O(NM) for updating at a singular data point and O(2NM + 4N + 5kM + 4k) for a minibatch. The only reason I have kept this in the longer notation is that I wanted to highlight if k &lt; N we will just go O(2NM + 4N + 5kM + 4k) =&gt; O(2NM + 4N) =&gt; O(2NM) =&gt; O(NM) but k = N, then we get O(2NM + 4N + 5NM + 4N) =&gt; O(7NM + 8N) =&gt; O(7NM) =&gt; O(NM). While the final big O is the same as k approaches N our time complexity gets significantly higher.\n Conclusion \nWe have explored various implementations of the perceptron algorithm seen how their accuracy can/can’t be affected my the separability and dimensionality. We know know that given the perceptron works in higher dimension just as well as lower dimensions. The main differentiator is how separable the data is and whether we are using a single step optimizer versus a minibatch optimizer. As our data gets more intertwined we want to start using the minibatch optimizer and a lower learning rate."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "CSCI 0451: Reflective Goal-Setting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Logistic Regression\n\n\n\n\n\nA blog post exploring logistic regression and its applications\n\n\n\n\n\nApr 20, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing the Perceptron Algorithm\n\n\n\n\n\nA blog post showing the capabitlities of the perceptron algorithm\n\n\n\n\n\nApr 20, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nReplication Study\n\n\n\n\n\nA blog post replicating a study on racial bias in medical risk algorithms\n\n\n\n\n\nApr 10, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nMid-Course Reflection\n\n\n\n\n\nWe reflect on our learning, engagement, and achievement in the first part of the semester. \n\n\n\n\n\nApr 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Descision Making\n\n\n\n\n\nA blog post exploring maximizing score functions for automated descision making algorithms\n\n\n\n\n\nMar 30, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nA blog post exploring predictive variables for penguin species\n\n\n\n\n\nMar 28, 2024\n\n\nJames Hetherington\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]